groups:
  # Application Health Alerts
  - name: application.rules
    rules:
      # Application is down
      - alert: ApplicationDown
        expr: up{job="laser-calc-app"} == 0
        for: 1m
        labels:
          severity: critical
          service: laser-calc-app
        annotations:
          summary: "Laser Calc application is down"
          description: "The Laser Calc application has been down for more than 1 minute on instance {{ $labels.instance }}"

      # High error rate
      - alert: HighErrorRate
        expr: rate(http_requests_total{status_code=~"5.."}[5m]) / rate(http_requests_total[5m]) > 0.05
        for: 5m
        labels:
          severity: critical
          service: laser-calc-app
        annotations:
          summary: "High error rate detected"
          description: "Error rate is {{ $value | humanizePercentage }} for the last 5 minutes on {{ $labels.instance }}"

      # High response time
      - alert: HighResponseTime
        expr: histogram_quantile(0.95, rate(http_request_duration_seconds_bucket[5m])) > 2
        for: 10m
        labels:
          severity: warning
          service: laser-calc-app
        annotations:
          summary: "High response time detected"
          description: "95th percentile response time is {{ $value }}s for the last 10 minutes on {{ $labels.instance }}"

      # Calculator errors
      - alert: CalculatorHighErrorRate
        expr: rate(calculator_errors_total[5m]) / rate(calculator_usage_total[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: laser-calc-calculators
        annotations:
          summary: "High calculator error rate"
          description: "Calculator {{ $labels.calculator_type }} has error rate of {{ $value | humanizePercentage }} for the last 5 minutes"

  # Infrastructure Alerts
  - name: infrastructure.rules
    rules:
      # High CPU usage
      - alert: HighCPUUsage
        expr: 100 - (avg by(instance) (irate(node_cpu_seconds_total{mode="idle"}[5m])) * 100) > 80
        for: 15m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High CPU usage detected"
          description: "CPU usage is {{ $value }}% on instance {{ $labels.instance }} for the last 15 minutes"

      # High memory usage
      - alert: HighMemoryUsage
        expr: (1 - (node_memory_MemAvailable_bytes / node_memory_MemTotal_bytes)) * 100 > 85
        for: 15m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "High memory usage detected"
          description: "Memory usage is {{ $value }}% on instance {{ $labels.instance }} for the last 15 minutes"

      # Low disk space
      - alert: DiskSpaceHigh
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 85
        for: 10m
        labels:
          severity: warning
          service: infrastructure
        annotations:
          summary: "Disk space running low"
          description: "Disk usage is {{ $value }}% on {{ $labels.device }} at {{ $labels.instance }}"

      # Critical disk space
      - alert: DiskSpaceCritical
        expr: (1 - (node_filesystem_avail_bytes / node_filesystem_size_bytes)) * 100 > 95
        for: 5m
        labels:
          severity: critical
          service: infrastructure
        annotations:
          summary: "Critical disk space"
          description: "Disk usage is {{ $value }}% on {{ $labels.device }} at {{ $labels.instance }}"

  # Database Alerts
  - name: database.rules
    rules:
      # Database is down
      - alert: DatabaseDown
        expr: up{job="postgres"} == 0
        for: 1m
        labels:
          severity: critical
          service: database
        annotations:
          summary: "PostgreSQL database is down"
          description: "PostgreSQL database has been down for more than 1 minute on instance {{ $labels.instance }}"

      # High database connections
      - alert: DatabaseConnectionsHigh
        expr: pg_stat_database_numbackends / pg_settings_max_connections > 0.8
        for: 5m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "High database connections"
          description: "Database connections are at {{ $value | humanizePercentage }} of maximum on {{ $labels.instance }}"

      # Slow queries
      - alert: DatabaseSlowQueries
        expr: rate(pg_stat_database_tup_returned[5m]) / rate(pg_stat_database_tup_fetched[5m]) < 0.1
        for: 10m
        labels:
          severity: warning
          service: database
        annotations:
          summary: "Database slow queries detected"
          description: "Query efficiency is {{ $value | humanizePercentage }} on database {{ $labels.datname }}"

  # Cache Alerts
  - name: cache.rules
    rules:
      # Redis is down
      - alert: CacheDown
        expr: up{job="redis"} == 0
        for: 1m
        labels:
          severity: critical
          service: cache
        annotations:
          summary: "Redis cache is down"
          description: "Redis cache has been down for more than 1 minute on instance {{ $labels.instance }}"

      # Low cache hit rate
      - alert: CacheHitRateLow
        expr: redis_keyspace_hits_total / (redis_keyspace_hits_total + redis_keyspace_misses_total) < 0.8
        for: 10m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "Low cache hit rate"
          description: "Cache hit rate is {{ $value | humanizePercentage }} on instance {{ $labels.instance }}"

      # High cache memory usage
      - alert: CacheMemoryHigh
        expr: redis_memory_used_bytes / redis_memory_max_bytes > 0.9
        for: 5m
        labels:
          severity: warning
          service: cache
        annotations:
          summary: "High cache memory usage"
          description: "Cache memory usage is {{ $value | humanizePercentage }} on instance {{ $labels.instance }}"

  # Business Logic Alerts
  - name: business.rules
    rules:
      # Low calculator usage
      - alert: LowCalculatorUsage
        expr: rate(calculator_usage_total[1h]) < 0.1
        for: 2h
        labels:
          severity: info
          service: business
        annotations:
          summary: "Low calculator usage detected"
          description: "Calculator {{ $labels.calculator_type }} usage is {{ $value }} requests/hour for the last 2 hours"

      # High user error rate
      - alert: HighUserErrorRate
        expr: rate(user_actions_total{action="error"}[10m]) / rate(user_actions_total[10m]) > 0.05
        for: 10m
        labels:
          severity: warning
          service: business
        annotations:
          summary: "High user error rate"
          description: "User error rate is {{ $value | humanizePercentage }} for the last 10 minutes"

      # Unusual traffic pattern
      - alert: UnusualTrafficPattern
        expr: rate(http_requests_total[5m]) > 2 * rate(http_requests_total[1h] offset 1h)
        for: 5m
        labels:
          severity: info
          service: business
        annotations:
          summary: "Unusual traffic pattern detected"
          description: "Current traffic rate {{ $value }} is significantly higher than historical average"

  # Security Alerts
  - name: security.rules
    rules:
      # High failed login attempts
      - alert: HighFailedLogins
        expr: rate(user_actions_total{action="login_failed"}[5m]) > 0.1
        for: 5m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "High failed login attempts"
          description: "Failed login rate is {{ $value }} attempts/second for the last 5 minutes"

      # Suspicious user activity
      - alert: SuspiciousUserActivity
        expr: rate(user_actions_total{action=~"admin_.*"}[5m]) > 0.05
        for: 5m
        labels:
          severity: warning
          service: security
        annotations:
          summary: "Suspicious admin activity detected"
          description: "Admin action rate is {{ $value }} actions/second for the last 5 minutes"

  # SSL Certificate Alerts
  - name: ssl.rules
    rules:
      # SSL certificate expiring soon
      - alert: SSLCertificateExpiringSoon
        expr: probe_ssl_earliest_cert_expiry - time() < 86400 * 30
        for: 1h
        labels:
          severity: warning
          service: ssl
        annotations:
          summary: "SSL certificate expiring soon"
          description: "SSL certificate for {{ $labels.instance }} expires in {{ $value | humanizeDuration }}"

      # SSL certificate expired
      - alert: SSLCertificateExpired
        expr: probe_ssl_earliest_cert_expiry - time() < 0
        for: 1m
        labels:
          severity: critical
          service: ssl
        annotations:
          summary: "SSL certificate expired"
          description: "SSL certificate for {{ $labels.instance }} has expired"
